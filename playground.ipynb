{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rng' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e23e41c2dbac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;31m# train iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIN_FEATS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0mnnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rng' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano.tensor as T\n",
    "import theano.tensor.nnet as F\n",
    "import theano\n",
    "\n",
    "\n",
    "class HiddenLayer(object):\n",
    "    def __init__(self, rng, ins, n_in, n_out, w=None, b=None, f=T.tanh):\n",
    "        # initial weight and bias\n",
    "        if w is not isinstance(w, np.ndarray):\n",
    "            w = np.asarray(\n",
    "                    rng.uniform(\n",
    "                        low=-np.sqrt(6. / (n_in + n_out)),\n",
    "                        high=np.sqrt(6. / (n_in + n_out)),\n",
    "                        size=(n_in, n_out)\n",
    "                    )\n",
    "                )\n",
    "            if f == theano.tensor.nnet.sigmoid:\n",
    "                w *= 4\n",
    "        if b is not isinstance(b, np.ndarray):\n",
    "            b = np.zeros((n_out,))\n",
    "       \n",
    "        w = theano.shared(w, borrow=True)\n",
    "        b = theano.shared(b, borrow=True)\n",
    "        \n",
    "        self.outs = T.dot(ins, w) - b\n",
    "        if f is not None:\n",
    "            # not a linear layer\n",
    "            self.outs = f(self.outs)\n",
    "        self.params = [w, b]\n",
    "        \n",
    "\n",
    "class NNet(object):\n",
    "    def __init__(self, data, gstep=0.01, epochs=1000, rng=None):\n",
    "        self.data = data\n",
    "        self.ins = data\n",
    "        self.n_sample, self.n_in = data.shape\n",
    "        self.gstep = gstep   # gradient step\n",
    "        self.layers = []\n",
    "        self.params = []\n",
    "        self.epochs = epochs\n",
    "        if rng is None:\n",
    "            self.rng = np.random\n",
    "        else:\n",
    "            self.rng = rng\n",
    "        \n",
    "    def add_layer(self, n_out, w=None, b=None, f=T.tanh):\n",
    "        layer = HiddenLayer(rng=self.rng,\n",
    "                            ins=self.ins,\n",
    "                            n_in=self.n_in,\n",
    "                            n_out=n_out,\n",
    "                            w=w, b=b, f=f)\n",
    "        self.layers.append(layer)\n",
    "        # the output of this layer is the input of next layer\n",
    "        self.ins = layer.outs\n",
    "        self.n_in = n_out\n",
    "        self.params += layer.params\n",
    "        \n",
    "    def train(self):\n",
    "        x = T.dmatrix(\"x\")\n",
    "        # calculate the gradients\n",
    "        gparams = T.grad(cost, [param for param in self.params])\n",
    "        updates = [(param, param - self.gstep * gparam) for param, gparam in zip(self.params, gparams)]\n",
    "        _train = theano.function(\n",
    "                  inputs=[x],\n",
    "                  outputs=self.cost,\n",
    "                  updates=updates,\n",
    "                  on_unused_input='ignore')\n",
    "        for i in range(self.epochs):\n",
    "            err = _train(self.data)\n",
    "            print(\"Epoch: %d; Distance: %f\" %(i+1, err))\n",
    "        \n",
    "    def set_cost(self, cost):\n",
    "        self.cost = cost\n",
    "    \n",
    "    def get_final_outs(self):\n",
    "        return self.layers[-1].outs\n",
    "    \n",
    "\n",
    "N = 5 # training sample size\n",
    "IN_FEATS = 50 # input feature space\n",
    "EPOCHS = 1000 # train iteration\n",
    "\n",
    "rng = np.random\n",
    "D = (rng.randn(N, IN_FEATS))      # inputs\n",
    "\n",
    "nnet = NNet(D)\n",
    "# encoder\n",
    "nnet.add_layer(100)\n",
    "# decoder\n",
    "nnet.add_layer(IN_FEATS)\n",
    "cost = ((nnet.get_final_outs() - D) ** 2).sum()\n",
    "nnet.set_cost(cost)\n",
    "nnet.train()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Autoencoder\n",
    "import numpy as np\n",
    "import theano.tensor as T\n",
    "import theano.tensor.nnet as F\n",
    "import theano\n",
    "\n",
    "N = 5 # training sample size\n",
    "IN_FEATS = 50 # input feature space, for encoder\n",
    "OUT_FEATS = 100 # output feature space, for decoder\n",
    "EPOCHS = 1000\n",
    "\n",
    "rng = np.random\n",
    "D = (rng.randn(N, IN_FEATS))      # inputs\n",
    "\n",
    "x = T.dmatrix(\"x\")\n",
    "\n",
    "e_w1 = theano.shared(rng.randn(IN_FEATS, OUT_FEATS), name=\"encode_w1\")  # weights\n",
    "e_b1 = theano.shared(np.zeros(OUT_FEATS), name=\"encode_b1\")             # bias\n",
    "d_w1 = theano.shared(rng.randn(OUT_FEATS, IN_FEATS), name=\"decode_w1\")\n",
    "d_b1 = theano.shared(np.zeros(IN_FEATS), name=\"decode_b1\")\n",
    "\n",
    "encoder = F.sigmoid(T.dot(x, e_w1) - e_b1)\n",
    "decoder = F.sigmoid(T.dot(encoder, d_w1) - d_b1)\n",
    "cost = ((decoder - x) ** 2).sum()\n",
    "e_gw1, e_gb1, d_gw1, d_gb1 = T.grad(cost, [e_w1, e_b1, d_w1, d_b1])\n",
    "\n",
    "train = theano.function(\n",
    "          inputs=[x],\n",
    "          outputs=cost,\n",
    "          updates=[(e_w1, e_w1 - 0.01*e_gw1), (e_b1, e_b1 - 0.01*e_gb1),\n",
    "                   (d_w1, d_w1 - 0.01*d_gw1), (d_b1, d_b1 - 0.01*d_gb1)])\n",
    "predict = theano.function(inputs=[x], outputs=encoder)\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    err = train(D)\n",
    "    print(\"Epoch: %d; Distance: %f\" %(i, err))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
